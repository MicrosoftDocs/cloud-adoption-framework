---
title: Responsible AI
description: Learn more about how Microsoft views the development of ethical AI, including principles, guidelines, and tools for accomplishing this.
author: v-hanki
ms.author: janet
ms.date: 06/25/2020
ms.topic: conceptual
ms.service: cloud-adoption-framework
ms.subservice: strategy
ms.custom: think-tank
---

<!-- cspell:ignore datasheets -->

# Responsible AI

Driven by ethical principles that put people first, Microsoft is committed to advancing AI. We want to partner with you to support this endeavor.

## Responsible AI principles

As you implement AI solutions, consider the following principles in your solution:

- **Fairness:** AI systems should treat all people fairly.
- **Reliability and safety:** AI systems should perform reliably and safely.
- **Privacy and security:** AI systems should be secure and respect privacy.
- **Inclusiveness:** AI systems should empower everyone and engage people.
- **Transparency:** AI systems should be understandable.
- **Accountability:** People should be accountable for AI systems.

## Establish a responsible AI strategy

Learn how to develop your own responsible AI strategy and principles based on the values of your organization.

- [Get started at AI Business School](https://www.microsoft.com/ai/ai-business-school?SilentAuth=1#primaryR7)

## Guidelines to develop AI responsibly

Put responsible AI into practice with these guidelines, designed to help you anticipate and address potential issues throughout the software development lifecycle.

- [Human-AI interaction guidelines](https://aka.ms/aiguidelines)
- [Conversational AI guidelines](https://www.microsoft.com/research/publication/responsible-bots/)
- [Inclusive design guidelines](https://www.microsoft.com/design/inclusive/)
- [AI fairness checklist](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA)
- [Datasheets for datasets template](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t8QB)
- [AI security engineering guidance](https://blogs.microsoft.com/on-the-issues/2019/12/06/ai-machine-learning-security/)

## Tools for responsible AI

Tools are available to help developers and data scientists understand, protect, and control AI systems. These tools can come from a variety of sources, including Azure Machine Learning, open-source projects, and research.

- **Understand:** AI systems can behave unexpectedly for a variety of reasons. Software tools can help you understand the behavior of your AI systems so that you can better tailor them to your needs. Examples of this type of tool include [InterpretML](https://github.com/interpretml/interpret), [Error Analysis](https://erroranalysis.ai/) and [Fairlearn](https://fairlearn.org/).
- **Protect:** AI systems rely on data. Software tools can help you protect that data by preserving privacy and ensuring confidentiality. Examples of this type of tool include [Confidential Computing for Machine Learning](https://azure.microsoft.com/solutions/confidential-compute/), [SmartNoise differential privacy toolkit](https://smartnoise.org/), [SEAL Homomorphic Encryption toolkit](https://www.microsoft.com/research/project/microsoft-seal/), and the [Presidio data de-identification toolkit](https://microsoft.github.io/presidio).
- **Control:** Responsible AI needs governance and control through the development cycle. Azure Machine Learning enables an audit trail for better traceability, lineage, and control to meet regulatory requirements. Examples include audit trail and traceability.

## Next steps

For more information about responsible solution development, visit:

- [Responsible AI overview](https://www.microsoft.com/ai/responsible-ai?activetab=pivot1:primaryr6)
- [Responsible AI resources](https://www.microsoft.com/ai/responsible-ai-resources)
- [Responsible bots: 10 guidelines for developers of conversational AI](https://www.microsoft.com/research/publication/responsible-bots/)
